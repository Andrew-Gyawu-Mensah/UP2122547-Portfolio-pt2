{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f38795",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf8db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define dimensions\n",
    "num_rows = 6\n",
    "num_cols = 4\n",
    "\n",
    "# Generate random data\n",
    "data = np.random.rand(num_rows, num_cols)\n",
    "\n",
    "# Create row and column labels\n",
    "row_labels = [f'Row{i+1}' for i in range(num_rows)]\n",
    "col_labels = [f'Col{j+1}' for j in range(num_cols)]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, index=row_labels, columns=col_labels)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Summary (info)\n",
    "print(\"\\nSummary (info):\")\n",
    "print(df.info())\n",
    "\n",
    "# Shape\n",
    "print(\"\\nShape of DataFrame:\")\n",
    "print(df.shape)\n",
    "\n",
    "# Statistics\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b73b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = sns.load_dataset('iris')\n",
    "\n",
    "# Display the first few rows (optional)\n",
    "print(\"First few rows of the Iris dataset:\")\n",
    "print(iris.head())\n",
    "\n",
    "# List of numerical columns\n",
    "numerical_cols = iris.select_dtypes(include=['float']).columns\n",
    "\n",
    "# Create boxplots for each numerical column\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, col in enumerate(numerical_cols, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.boxplot(iris[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "    plt.ylabel(col)\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf7872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Load the Tips dataset\n",
    "tips = sns.load_dataset('tips')\n",
    "\n",
    "# Group the data by sex, day, and time, then sum the tips\n",
    "grouped = tips.groupby(['sex', 'day', 'time'])['tip'].sum().reset_index()\n",
    "\n",
    "# Create the sunburst chart\n",
    "fig = px.sunburst(\n",
    "    grouped,\n",
    "    path=['sex', 'day', 'time'],  # hierarchy: sex → day → time\n",
    "    values='tip',\n",
    "    title='Total Tips by Gender, Day, and Time',\n",
    "    color='tip',\n",
    "    color_continuous_scale='Blues'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530095db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Load the Tips dataset\n",
    "tips = sns.load_dataset('tips')\n",
    "\n",
    "# Define the feature and target variable\n",
    "X = tips[['total_bill']]  # Feature\n",
    "y = tips['tip']           # Target\n",
    "\n",
    "# Initialize and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Display model parameters\n",
    "print(f\"Intercept: {model.intercept_:.2f}\")\n",
    "print(f\"Coefficient: {model.coef_[0]:.2f}\")\n",
    "\n",
    "# Predict tip for a total bill of $30\n",
    "sample_bill = np.array([[30]])\n",
    "predicted_tip = model.predict(sample_bill)\n",
    "print(f\"Predicted tip for a $30 bill: ${predicted_tip[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686b6390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = 'https://raw.githubusercontent.com/Koldim2001/test_api/refs/heads/main/titanic.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Select and preprocess features\n",
    "features = ['Pclass', 'Age', 'Fare', 'SibSp', 'Parch', 'Sex', 'Embarked']\n",
    "df = df[['Survived'] + features]\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Define categorical and numerical columns\n",
    "cat_features = ['Sex', 'Embarked']\n",
    "num_features = ['Pclass', 'Age', 'Fare', 'SibSp', 'Parch']\n",
    "\n",
    "# One-hot encode categorical features\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(drop='first'), cat_features)\n",
    "], remainder='passthrough')  # keep numerical as-is\n",
    "\n",
    "# Split dataset\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Separate X and y\n",
    "X_train = train.drop(columns='Survived')\n",
    "y_train = train['Survived']\n",
    "X_test = test.drop(columns='Survived')\n",
    "y_test = test['Survived']\n",
    "\n",
    "# Build pipeline\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(max_depth=5, min_samples_split=150, random_state=42))\n",
    "])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "preds = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Updated model accuracy:\", acc)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, preds, target_names=['Not Survived', 'Survived']))\n",
    "\n",
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    ticks = np.arange(len(classes))\n",
    "    plt.xticks(ticks, classes, rotation=45)\n",
    "    plt.yticks(ticks, classes)\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_confusion_matrix(cm, classes=['Not Survived', 'Survived'])\n",
    "\n",
    "# Save model\n",
    "with open('../outputs/models/model_dt_updated.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Predict for a new person\n",
    "new_passenger = pd.DataFrame({\n",
    "    'Pclass': [3],\n",
    "    'Age': [55],\n",
    "    'Fare': [7.25],\n",
    "    'SibSp': [0],\n",
    "    'Parch': [0],\n",
    "    'Sex': ['male'],\n",
    "    'Embarked': ['S']\n",
    "})\n",
    "\n",
    "prediction = model.predict(new_passenger)\n",
    "print(f\"\\nPrediction for new passenger: {prediction}\")\n",
    "print(\"This person is most likely a survivor.\" if prediction[0] == 1 else \"This person most likely perished.\")\n",
    "\n",
    "# Extract feature names after encoding\n",
    "feature_names = list(model.named_steps['preprocessor'].get_feature_names_out()) + num_features\n",
    "\n",
    "# Feature importance\n",
    "tree_model = model.named_steps['classifier']\n",
    "importances = tree_model.feature_importances_\n",
    "\n",
    "# Get one-hot encoded feature names\n",
    "ohe_feature_names = model.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(['Sex', 'Embarked'])\n",
    "\n",
    "# Combine them with numeric feature names\n",
    "full_feature_names = list(ohe_feature_names) + num_features\n",
    "\n",
    "# Get importances from the classifier\n",
    "tree_model = model.named_steps['classifier']\n",
    "importances = tree_model.feature_importances_\n",
    "\n",
    "# Ensure they are the same length\n",
    "print(\"Feature names:\", len(full_feature_names))\n",
    "print(\"Importances:\", len(importances))\n",
    "\n",
    "# Now create DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': full_feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "assert len(full_feature_names) == len(importances), \"Mismatch between features and importances!\"\n",
    "\n",
    "\n",
    "# Bar chart of feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=importance_df, x='importance', y='feature', palette='viridis')\n",
    "plt.title(\"Feature Importance in Decision Tree\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "def experiment(max_depth, min_samples_split):\n",
    "    \"\"\"\n",
    "    Builds and trains Decision Tree model\n",
    "    \"\"\"\n",
    "    # Build and train Decision Tree model\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, random_state=42)\n",
    "    model.fit(train.drop('Survived', axis=1), train['Survived'])\n",
    "\n",
    "    # Calculate accuracy metrics\n",
    "    preds = model.predict(test.drop('Survived', axis=1))\n",
    "    acc = accuracy_score(test['Survived'], preds)\n",
    "    cm = confusion_matrix(test['Survived'], preds)\n",
    "\n",
    "    print(\"accuracy\", acc)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(cm, classes=['Not Survived', 'Survived'])\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(test['Survived'], preds, target_names=['Not Survived', 'Survived'])\n",
    "    print(report)\n",
    "\n",
    "    # Save model in pickle format\n",
    "    with open('../outputs/models/model_dt.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36cf1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = 'https://raw.githubusercontent.com/Koldim2001/test_api/refs/heads/main/titanic.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Select and preprocess features\n",
    "features = ['Pclass', 'Age', 'Fare', 'SibSp', 'Parch', 'Sex', 'Embarked']\n",
    "df = df[['Survived'] + features]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Define categorical and numerical columns\n",
    "cat_features = ['Sex', 'Embarked']\n",
    "num_features = ['Pclass', 'Age', 'Fare', 'SibSp', 'Parch']\n",
    "\n",
    "# One-hot encode categorical features\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(drop='first'), cat_features)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Split dataset\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "X_train = train.drop(columns='Survived')\n",
    "y_train = train['Survived']\n",
    "X_test = test.drop(columns='Survived')\n",
    "y_test = test['Survived']\n",
    "\n",
    "# Build and train pipeline\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(max_depth=5, min_samples_split=150, random_state=42))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "preds = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "print(\"Updated model accuracy:\", acc)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, preds, target_names=['Not Survived', 'Survived']))\n",
    "\n",
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    ticks = np.arange(len(classes))\n",
    "    plt.xticks(ticks, classes, rotation=45)\n",
    "    plt.yticks(ticks, classes)\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_confusion_matrix(cm, classes=['Not Survived', 'Survived'])\n",
    "\n",
    "# Save model\n",
    "with open('../outputs/models/model_dt_updated.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Predict for new passenger\n",
    "new_passenger = pd.DataFrame({\n",
    "    'Pclass': [3],\n",
    "    'Age': [55],\n",
    "    'Fare': [7.25],\n",
    "    'SibSp': [0],\n",
    "    'Parch': [0],\n",
    "    'Sex': ['male'],\n",
    "    'Embarked': ['S']\n",
    "})\n",
    "prediction = model.predict(new_passenger)\n",
    "print(f\"\\nPrediction for new passenger: {prediction}\")\n",
    "print(\"This person is most likely a survivor.\" if prediction[0] == 1 else \"This person most likely perished.\")\n",
    "\n",
    "# Feature importance\n",
    "ohe_feature_names = model.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(cat_features)\n",
    "full_feature_names = list(ohe_feature_names) + num_features\n",
    "importances = model.named_steps['classifier'].feature_importances_\n",
    "\n",
    "assert len(full_feature_names) == len(importances), \"Mismatch between features and importances!\"\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': full_feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=importance_df, x='importance', y='feature', palette='viridis')\n",
    "plt.title(\"Feature Importance in Decision Tree\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize decision tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(model.named_steps['classifier'], \n",
    "          feature_names=full_feature_names, \n",
    "          class_names=['Not Survived', 'Survived'], \n",
    "          filled=True, max_depth=5)\n",
    "plt.title(\"Decision Tree Visualization\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Training vs validation error plot\n",
    "errors_list = []\n",
    "for md in range(1, 21):\n",
    "    temp_model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', DecisionTreeClassifier(max_depth=md, random_state=42))\n",
    "    ])\n",
    "    temp_model.fit(X_train, y_train)\n",
    "    train_err = 1 - temp_model.score(X_train, y_train)\n",
    "    test_err = 1 - temp_model.score(X_test, y_test)\n",
    "    errors_list.append({'Max Depth': md, 'Training Error': train_err, 'Validation Error': test_err})\n",
    "\n",
    "errors_df = pd.DataFrame(errors_list)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(errors_df['Max Depth'], errors_df['Training Error'], marker='o', label='Training Error')\n",
    "plt.plot(errors_df['Max Depth'], errors_df['Validation Error'], marker='o', label='Validation Error')\n",
    "plt.title(\"Training vs Validation Error by Tree Depth\")\n",
    "plt.xlabel(\"Max Tree Depth\")\n",
    "plt.ylabel(\"Prediction Error (1 - Accuracy)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
